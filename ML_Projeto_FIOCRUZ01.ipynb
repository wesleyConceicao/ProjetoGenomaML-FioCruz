{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bdb0b376",
   "metadata": {},
   "source": [
    "# Sobre o Conjunto de Dados\n",
    "\n",
    "### Modelagem ML para identificar a relação de genomas com os genes ortólogos\n",
    "\n",
    "Analise do dataset com os outcomes (0 não patógenos e 1 patógeno). \n",
    "As variáveis (OG grupos de genes ortólogos) estão nas colunas e nas linhas estão as instâncias (genomas). \n",
    "Inicialmente tente descobrir os OG envolvidos na patogênese, os módulos funcionais (os OG que estão atuando em conjunto).\n",
    "\n",
    "Dicas: A presença do gene é mais importante do que ausências! Ou seja, o(s) gene(s) precisam estar lá para desempenhar a interação com o hospedeiro e a função da patogênese. \n",
    "Alguns não patógenos podem ter alguns poucos genes de virulência também\n",
    "mas é preciso ter a grande maioria deles para ser um patógeno eficiente de importância clínica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a0316f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b271cd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10400\\370090811.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"C:\\\\Users\\\\wesle\\\\Projetos_Estudo_Analise-de-Dados\\\\Notebooks\\\\ML_Dashboard\\\\dataset.csv.gz\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[0;32m   5444\u001b[0m             \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5446\u001b[1;33m         \u001b[0msampled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5447\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampled_indices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\sample.py\u001b[0m in \u001b[0;36msample\u001b[1;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid weights: weights sum to zero\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m     return random_state.choice(obj_len, size=size, replace=replace, p=weights).astype(\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     )\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "with gzip.open(\"C:\\\\Users\\\\wesle\\\\Projetos_Estudo_Analise-de-Dados\\\\Notebooks\\\\ML_Dashboard\\\\dataset.csv.gz\", 'rb') as f:\n",
    "    df = pd.read_csv(f,sep=',').sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d9e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns= {\"GENOME\" :\"Genome\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9f5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Target'] = df['Target'].apply(lambda x : 1 if(x == True) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4a3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(\"Genome\", inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9dd2d3",
   "metadata": {},
   "source": [
    "### Analise de Frequencias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8d6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Freq'] = ((df['Target']/df.groupby('Target')['Target'].transform('sum'))*100).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a5a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='Freq', ascending=False, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8634a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = df[df['Freq'] >= 25.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575a27c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85cb9dd",
   "metadata": {},
   "source": [
    "## Modelo de machine Learning\n",
    "\n",
    "### Vamos começar a preparar os dados para testar um modelo de classificação\n",
    "\n",
    "### Separe o conjunto de dados em dois grupos: treino e teste nas proporções de 70% e 30% respectivamente.\n",
    "\n",
    "* Lembre-se que primeiro vai ser preciso separar as features do target antes de usar o train_test_split. Nosso target é a coluna 'Status'.\n",
    "* Estamos lidando com dados desbalanceados, então pode ser legal setar o argumento stratify do train_test_split usando a variável target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e39b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indicando as variáveis “x” e “y” estamos dizendo que queremos separar estas duas variáveis em dois grupos, sendo que com o parâmetro “test_size = 0.3” \n",
    "# determinamos que os dados de teste receberão 30% dos dados, e os dados de treino 70%. Como estamos dividindo duas bases\n",
    "# como resultado teremos quatro bases, sendo que cada uma será salva na respectiva variável.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Criamos então a variável “y” com os dados da coluna “target”, ou seja, os dados que iremos prever. Criamos também a variável “x” com as demais colunas do dataset, que são as variáveis preditoras.\n",
    "\n",
    "x = df_freq.drop(columns = [\"Target\", 'Freq'], axis = 1)\n",
    "y = df_freq['Target']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.4)\n",
    "\n",
    "print(x_train.shape, \n",
    "      x_test.shape, \n",
    "      y_train.shape,\n",
    "      y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770f9c18",
   "metadata": {},
   "source": [
    "## HeatMap de Correlação "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea352b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a00ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([x_train, y_train], axis=1)\n",
    "print(df_train.shape)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf06880",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "sn.heatmap(df_train.corr(), annot=True, cmap='magma');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d50aac2",
   "metadata": {},
   "source": [
    "### Plot SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f312db7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# load JS visualization code to notebook\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9d1ad5",
   "metadata": {},
   "source": [
    "### Agora vamos treinar uma Árvore de Decisão nos dados de treino\n",
    "* Comece com uma primeira versão definindo apenas o parâmetro max_depth = 3\n",
    "* Dica: Não é preciso reescalonar as variáveis numéricas porque estamos usando uma Decision Tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6298239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtraTrees, que criará várias árvores de decisão\n",
    "# Este algoritmo está pronto para ser utilizado \n",
    "# sendo que precisamos apenas indicar sua função\n",
    "# Como estamos trabalhando em um problema de classificação utilizaremos a função “ExtraTreesClassifier()”.\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "model_decisiontree = ExtraTreesClassifier()\n",
    "\n",
    "model_decisiontree.fit(x_train,y_train)\n",
    "\n",
    "acc_decisiontree = round(model_decisiontree.score(x_test, y_test)*100,2)\n",
    "\n",
    "acc_decisiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf04c5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model_decisiontree = shap.TreeExplainer(model_decisiontree)\n",
    "shap_test_model_decisiontree = explainer_model_decisiontree.shap_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer_model_decisiontree.expected_value, shap_test_model_decisiontree, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5d7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_test_model_decisiontree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66473110",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c04cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uma floresta aleatória é um meta estimador que ajusta uma série de árvores de decisão de classificação em várias subamostras do conjunto de dados \n",
    "# e usa a média para melhorar a precisão preditiva e controlar o ajuste excessivo\n",
    "\n",
    "#Train the model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model_RandomForestRegressor = RandomForestRegressor(n_estimators=100)\n",
    "#Fit\n",
    "\n",
    "model_RandomForestRegressor.fit(x_train,y_train)\n",
    "\n",
    "#Score/Accuracy\n",
    "acc_randomforest=round(model_RandomForestRegressor.score(x_test, y_test)*100,2)\n",
    "\n",
    "acc_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8d6f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model_RandomForestRegressor = shap.TreeExplainer(model_RandomForestRegressor)\n",
    "shap_test_model_RandomForestRegressor = explainer_model_RandomForestRegressor.shap_values(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbfe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer_model_RandomForestRegressor.expected_value[1], shap_test_model_RandomForestRegressor[][0,:], x_test.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_test_model_decisiontree[1], x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = shap.Explainer(model_RandomForestRegressor)\n",
    "# shap_test = explainer(x_test)\n",
    "# shap.summary_plot(shap_test)\n",
    "# print(f\"Shap values length: {len(shap_test)}\\n\")\n",
    "# print(f\"Sample shap value:\\n{shap_test[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82183105",
   "metadata": {},
   "source": [
    "## Regressão Logistica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa031aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model_LogisticRegression = LogisticRegression()\n",
    "\n",
    "# #Fit the model\n",
    "# model_LogisticRegression.fit(x_train,y_train)\n",
    "\n",
    "# y_pred = model_LogisticRegression.predict(x_test)\n",
    "\n",
    "# #Score/Accuracy\n",
    "# acc_logreg=round(model_LogisticRegression.score(x_test, y_test)*100,2)\n",
    "\n",
    "# acc_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4318d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_model_LogisticRegression = shap.LinearExplainer(model_LogisticRegression, x_train, feature_dependence=\"independent\")\n",
    "shap_test_model_LogisticRegression = explainer_model_LogisticRegression(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f318347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_test_model_decisiontree[1], x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ff4829",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14ef7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "# df_train = pd.read_csv(\"data/dataset.csv\").sample(10000)\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x, y)\n",
    "xgb_scores = cross_val_score(xgb, x, y, cv=10, scoring='roc_auc')\n",
    "xgb_score = np.mean(xgb_scores)\n",
    "print(\"XGB - AUC (ROC): \", xgb_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
